{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is a popular ensemble learning technique in traditional machine learning. However, it's worth mentioning in the context of deep learning for comparison.\n",
    "\n",
    "Random Forest is an ensemble method that operates by constructing multiple decision trees and combines their predictions. Each decision tree in a Random Forest is trained independently on a random subset of the training data and a random subset of the features. This randomness helps to reduce overfitting and improve generalization performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_data1=pd.read_csv('nlp_data1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import joblib\n",
    "\n",
    "X = nlp_data1['lemmatized_token']\n",
    "y = nlp_data1['target']\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X = tfidf_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform cross-validation for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "Accuracy: mean = 0.7832512315270936 , std = 0.011459012362803233\n",
      "Precision: mean = 0.8221843977594278 , std = 0.01423455577882111\n",
      "Recall: mean = 0.6334918211559433 , std = 0.018528972801276643\n",
      "F1 Score: mean = 0.7155511741786925 , std = 0.016516671629865174\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for name, model in models.items():\n",
    "    print(\"Model:\", name)\n",
    "    cv_results = cross_validate(model, X_train, y_train, cv=5,\n",
    "                                scoring=['accuracy', 'precision', 'recall', 'f1'])\n",
    "    \n",
    "    # Access the cross-validation results\n",
    "    accuracy_scores = cv_results['test_accuracy']\n",
    "    precision_scores = cv_results['test_precision']\n",
    "    recall_scores = cv_results['test_recall']\n",
    "    f1_scores = cv_results['test_f1']\n",
    "\n",
    "    # Print the mean and standard deviation of each metric\n",
    "    print(\"Accuracy: mean =\", np.mean(accuracy_scores), \", std =\", np.std(accuracy_scores))\n",
    "    print(\"Precision: mean =\", np.mean(precision_scores), \", std =\", np.std(precision_scores))\n",
    "    print(\"Recall: mean =\", np.mean(recall_scores), \", std =\", np.std(recall_scores))\n",
    "    print(\"F1 Score: mean =\", np.mean(f1_scores), \", std =\", np.std(f1_scores))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Trained Model Using Joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as Random_Forest_model.joblib\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(model, f'{name.replace(\" \", \"_\")}_model.joblib')\n",
    "print(\"Model saved as\", f'{name.replace(\" \", \"_\")}_model.joblib')\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
